Week 2 Practice Quiz

Q.Below are plots of the prior distribution for a parameter $\theta$ and the likelihood as a function of $\theta$ based on 10 observed data points.


```{r}
x<-seq(0,10,by=0.01)
prior<-dgamma(x,2,1)
likelihood<-dnorm(x,4,0.5)/1e6
posterior<-prior*likelihood
plot(x,likelihood,type="l",col="red",ylim=c(0,.000001))
lines(x,posterior,col="black")
lines(x,prior,col="blue")
```

Q. Suppose that you sample 24 M&Ms from a bag and find that 3 of them are yellow. Assuming that you place a uniform Beta(1,1) prior on the proportion of yellow M&Ms p, what is the posterior probability that p < 0.2 ?

```{r}
pbeta(0.2, 4, 22)
```

Q. Suppose you are given a coin and told that the coin is either biased towards heads (p = 0.6) or biased towards tails (p = 0.4). Since you have no prior knowledge about the bias of the coin, you place a prior probability of 0.5 on the outcome that the coin is biased towards heads. You flip the coin twice and it comes up tails both times. What is the posterior probability that your next two flips will be heads?

http://www.r-tutor.com/elementary-statistics/probability-distributions/binomial-distribution

```{r}
# Find the probability of having 2 tails
p=c(0.4,0.6)
prior=c(0.5,0.5)
likelihood=dbinom(0,size=2,p=p)
posterior=(prior*likelihood)/sum(prior*likelihood)
posterior

# Find the probability of having 2 heads after 2 tails
sum(dbinom(2,size=2,p=p) * posterior)
```

Q You are trying to model the number of fireworks that go off per minute during a fireworks show. You decide to model this with a Poisson distribution with rate ??, imposing a Gamma prior on ?? for conjugacy. You want the prior to have mean equal to 3 and standard deviation equal to 1. Which of the following priors represents your beliefs?

```{r}
# Gamma(k=9,??=1/3)
```

Q. If John is trying to perform a Bayesian analysis to make inferences about the proportion of defective electric toothbrushes, which of the following distributions represents the a conjugate prior for the proportion p ?

```{r}
# Beta
```

Q. You are hired as a data analyst by politician A. She wants to know the proportion of people in Metrocity who favor her over politician B. From previous poll numbers, you place a Beta(40,60) prior on the proportion. From polling 200 randomly sampled people in Metrocity, you find that 103 people prefer politician A to politician B. What is the posterior probability that the majority of people prefer politician A to politican B (i.e. P(p>0.5|data))?

```{r}
posterior_a = 40 + 103
posterior_b = 60 + 200 - 103
qbeta(c(0.025, 0.975), posterior_a, posterior_b)

pbeta(0.5, posterior_a, posterior_b, lower.tail = FALSE)

# Detailed
p=seq(from=0, to=1, by=0.00001)
prior=dbeta(p,shape1=40,shape2=60)
likelihood=dbinom(103,size=200,p=p)
posterior=(prior*likelihood)/sum(prior*likelihood)
sum(posterior[p>0.5])
```

Q. Suppose that the number of fish that Hans catches in an hour follows a Poisson distribution with rate ??. If the prior on ?? is Gamma(1,1) and Hans catches no fish in five hours, what is the posterior distribution for ???

```{r}
# Gamma(k=49.5,??=2/11)
k_prior = 1+0
theta_prior = 1/(5*1+1)
```

Q. A young meteorologist is trying to estimate the expected number of tropical cyclones that occur in a given year. He assumes that the number of observed tropical cyclones in a year follows a Poisson distribution with rate ?? that is consistent across years. Because the meteorologist is inexperienced, he assigns a relatively uninformative Gamma(k=.5,??=2) prior distribution to ??. During his first five years, he observes a total of 49 cyclones. If he were to collect more data about tropical cyclones in future years, what should his prior be?

```{r}
k_prior = 0.5+49
theta_prior = 2/(5*2+1)
```

Q. Suppose you are given a coin and told that the die is either biased towards heads (p = 0.75 ) or biased towards tails (p = 0.25 ). Since you have no prior knowledge abou the bias of the coin, you place a prior probability of 0.5 on the outcome that the coin is biased towards heads. You flip the coin twice and it comes up tails both times. What is the posterior probability that your next flip will be heads?

```{r}
# Find the probability of having 2 tails
p=c(0.25,0.75)
prior=c(0.5,0.5)
likelihood=dbinom(0,size=2,p=p)
likelihood
posterior=(prior*likelihood)/sum(prior*likelihood)
posterior
# Find the probability of 1 head after 2 tails
sum(dbinom(1,size=1,p=p) * posterior)
```

Q. Suppose that a miner finds a gold nugget and wants to know the weight of the nugget in order to assess its value. The miner believes the nugget to be roughly 200 grams, although she is uncertain about this quantity, so she puts a standard deviation of 50 grams on her estimate. She weighs the nugget on a scale which is known to weigh items with standard deviation 2 grams. The scale measures the nugget at 149.3 grams. What distribution summarizes the posterior beliefs of the miner?
```{r}
v=200
t=50
sd=2
sample_mean=149.3
n=1
mean= (v*sd**2+n*sample_mean*t**2) / (sd**2 +n*t**2)
sd = sqrt((sd**2 * t**2)/(sd**2 +n*t**2))
mean
sd
```

Q. A scientist is interested in estimating the average weight of male golden hamsters. They decide to use a Bayesian approach to estimate ?? by creating a credible interval using a weakly informative prior. The posterior distribution gives a 95% credible interval spanning 3.3 - 4.0 oz. According to this model, what is the probability that ?? does not fall within this range?
```{r}
# 5%
```

Q. Suppose you are given a die and told that the die is either fair or is loaded (it always comes up as a 6). Since most dice are not loaded, you place a prior probability of 0.8 on the outcome that the die is fair. You roll a die and it comes up as a 6. What is the posterior probability that your next roll will also be a 6?
```{r}
p=c(1/6, 1)
prior=c(0.8,0.2)
likelihood=c(dbinom(1,1,1/6), dbinom(1,1,1))
posterior=(prior*likelihood)/sum(prior*likelihood)
posterior

# What is the posterior probability that your next roll will also be a 6?
sum(posterior*p)
```